# Chatbot Universitario - Backend

Prototipo inicial del Chatbot Inteligente para Soporte TÃ©cnico Universitario.
Desarrollado en Python con FastAPI y un modelo simple de NLU basado en Naive Bayes.

## Ejecutar localmente

1. Crear entorno virtual
   ```bash
   python -m venv venv
   venv\Scripts\Activate.ps1
   ```

2. Instalar dependencias
   ```bash
   pip install -r requirements.txt
   python -m spacy download es_core_news_md
   ```

3. Iniciar servidor
   ```bash
   uvicorn app.main:app --reload
   ```

4. Probar API en: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

DocumentaciÃ³n de las librerias utilizadas

ğŸ§© fastapi
Framework moderno y rÃ¡pido para construir APIs web en Python.
Permite crear endpoints REST de forma sencilla, con validaciÃ³n automÃ¡tica de datos y una interfaz interactiva (/docs).
ğŸ‘‰ En tu chatbot, se usa para exponer el servicio que recibe los mensajes del usuario y devuelve la respuesta del bot.

âš¡ uvicorn
Servidor web ligero y asÃ­ncrono compatible con FastAPI.
Se encarga de ejecutar la API y manejar las peticiones HTTP.
ğŸ‘‰ Es el motor que â€œlevantaâ€ tu backend y permite acceder a Ã©l desde el navegador o el frontend (por ejemplo, http://127.0.0.1:8000).

ğŸ“Š scikit-learn
Conjunto de herramientas para Machine Learning clÃ¡sico en Python.
Incluye modelos de clasificaciÃ³n, regresiÃ³n y procesamiento de texto.
ğŸ‘‰ En tu chatbot se usa para entrenar el modelo que clasifica las intenciones del usuario (por ejemplo, distinguir entre â€œproblemas de conexiÃ³nâ€ o â€œacceso al LMSâ€).

ğŸ§  BeautifulSoup
LibrerÃ­a para analizar y extraer informaciÃ³n de documentos HTML o XML.
Permite navegar la estructura del DOM, seleccionar etiquetas y limpiar texto de forma sencilla.
ğŸ‘‰ En este proyecto se usa durante la etapa de scraping, donde se extraen preguntas y respuestas desde una pÃ¡gina HTML institucional para generar automÃ¡ticamente el conjunto de datos.
Los pasos realizados con BeautifulSoup son:

Leer el archivo HTML con el contenido de las preguntas frecuentes.
Identificar las secciones, tÃ­tulos y respuestas dentro del DOM.
Limpiar el texto de etiquetas y espacios innecesarios.
Generar un JSON estructurado con intents, examples y responses que luego alimenta el modelo de clasificaciÃ³n.
